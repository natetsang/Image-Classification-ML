{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS200A Computer Vision Project\n",
    "---\n",
    "## Summary\n",
    "This project consists of a large dataset with images belonging to 20 different categories.\n",
    "The goal is to classify the category of a given image using a machine learning model. We are\n",
    "given 1501 images to train our models, and 716 images to evaluate the model accuracies. We\n",
    "began by performing exploratory data analyses to give us insights into the feature selection\n",
    "process. Then, we trained 4 models: Logistic Regression, KNN, SVM and Random Forest. For\n",
    "each model, we used cross validation to select the best parameters, and a feature selection\n",
    "function to select the top 10 features. In the end, we identified Logistic Regression as the best\n",
    "model because it has one of the lowest validation errors, a fast computation time and is\n",
    "relatively easy to interpret.\n",
    "\n",
    "## Key questions explored\n",
    "- How well can I design a image classifier using conventional (i.e. non-neural net) ML models?\n",
    "\n",
    "## Techniques used\n",
    "- logistic regression\n",
    "- KNN\n",
    "- SVM\n",
    "- Random forest\n",
    "- bootstrapping\n",
    "- cross validation\n",
    "- feature engineering\n",
    "\n",
    "## Key findings\n",
    "- One of the most significant factors that affected model accuracy was the preprocessing of feature values. When normalizing the data, the model performed 10-50% worse compared to models trained on the original data. In contrast, models trained on scaled feature values performed significantly better than the original data.\n",
    "- Our models achieved a validation accuracy of 40%-46%, with SVM performing the highest (46% accuracy) and KNN performing the lowest (40% accuracy). They also achieved a The 95% confidence interval for SVM was between 38-54%. We selected the Logistic Regression model to predict the test set because it had descent accuracy, is a simple model that’s easy to interpret, and it didn’t overfit the train data as much as some of the other models. We expect this model to generalize best to the test data.\n",
    "- In this project, we limited our features to numerical values only. However, it is possible to use a pixel by pixel matrix as a feature, which could be significantly improve the final model. Despite the feature constraints presented in this project, we were still able to achieve almost a 50% accuracy on the validation set by focusing our efforts on transforming the data and optimizing model parameters to increase model accuracy. It would be interesting to see how much we could improve the model accuracy by if we combine our data cleaning and parameter optimization efforts in this project with more powerful features.\n",
    "\n",
    "This image shows a snapshot of the results from different ML models.\n",
    "![Results comparison](summary_results.png)\n",
    "\n",
    "This image shows the breakdown of categories in the dataset.\n",
    "![Distribution of categories in train data](category_dist.png)\n",
    "\n",
    "## Notebooks\n",
    "This project is split into 4 notebooks. When running for the first time, the notebooks should be opened and ran in sequential order. After all files have been downloaded, they can be opened and executed individually. \n",
    "- __NB1: Data cleaning and preparation__\n",
    "- __NB2a: Preliminary EDA__\n",
    "- __NB2b: Feature selection__\n",
    "- __NB3: Modeling__\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation (NB1) - Table of contents\n",
    "> ### Part 1. [Access zipped files](#zip)\n",
    "> ### Part 2. [Read data and clean](#set_parameters)\n",
    "> ### Part 3. [Confirm images in proper format](#confirm)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import os\n",
    "import zipfile \n",
    "from zipfile import ZipFile\n",
    "import re \n",
    "from skimage import io\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"zip\"></a>\n",
    "### Part 1. Define functions to assist in data preparation/cleaning\n",
    "As part of our class project, we are given two zip files that contain images. Therefore, our first task is to unzip these files for access. We need to ensure that 1. file names have no spaces and 2. data is in correct RGB format. In particular, there are spaces in the file names for the test set, which are causing issues. Also, not all images are in RGB format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Remove spaces from specified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_directory_file_spaces_zip(dir_name='20_Validation'): \n",
    "    \"\"\"\n",
    "    Removes spaces in file names of specified directory in zip file.\n",
    "    The zip file name should be specified from the root directory. \n",
    "    Extracts the zip file, trims the filenames and rezips the file.\n",
    "    \n",
    "    Keyword arguments: \n",
    "    dir_name (string) -- name of zip file in root folder \n",
    "    \n",
    "    Returns: \n",
    "        None \n",
    "    \"\"\"\n",
    "    # Find and extract zip files\n",
    "    val_files_zip = zipfile.ZipFile(f\"{os.getcwd()}/{dir_name}.zip\")\n",
    "    val_files_zip.extractall(f\"{os.getcwd()}/{dir_name}/\")\n",
    "    \n",
    "    # Remove spaces from file names\n",
    "    current_directory = os.getcwd()\n",
    "    directory = f\"{current_directory}/{dir_name}\"\n",
    "    [os.rename(os.path.join(directory, f), \n",
    "               os.path.join(directory, f).replace(' ', '').lower()) \n",
    "     for f in os.listdir(directory)]\n",
    "    \n",
    "    # Rezip files and close\n",
    "    zf = ZipFile(f\"{dir_name}.zip\", \"w\")\n",
    "    for dirname, subdirs, files in os.walk(directory): \n",
    "        for filename in files:\n",
    "            zf.write(os.path.join(dirname, filename), filename)\n",
    "    zf.close()\n",
    "    \n",
    "remove_directory_file_spaces_zip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Convert greyscale images into RGB\n",
    "Some files are in greyscale. For consistency in the structure of data, convert these into a representative RGB format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gray(images):\n",
    "    \"\"\"\n",
    "    Creates RGB representation of gray-level images. \n",
    "    \n",
    "    Keyword arguments: \n",
    "    images (pd.Series) -- array containing image pixels \n",
    "    \n",
    "    Returns: \n",
    "        ndarray of images all with RGB representation\n",
    "        \n",
    "    \"\"\"\n",
    "    return images.apply(lambda image: skimage.color.grey2rgb(image) if len(image.shape) < 3 else image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read\"></a>\n",
    "\n",
    "### Part 2. Read image data and create cleaned dataframe\n",
    "Take a given folder and create a dataframe with the picture object, and the encoding as listed below.\n",
    "\n",
    "0=Airplanes, 1=Bear, 2=Blimp, 3=Comet, 4=Crab, 5=Dog, 6=Dolphin, 7=Giraffe, 8=Goat, 9=Gorilla, 10=Kangaroo, 11=Killer-Whale, 12=Leopards, 13=Llama, 14= Penguin, 15= Porcupine, 16=Teddy-Bear, 17=Triceratops, 18=Unicorn, 19=Zebra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create functions to assist in data cleaning/preparation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_organize_data(folder_name='20_categories_training', isTest=False, isCache=True):    \n",
    "    \"\"\"\n",
    "    Returns a dataframe with picture objects and category encodings of all images in folder. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    folder_name (string) -- name of image folder in root directory \n",
    "    isTest (bool) -- Flag. True loads images from test set, False loads train set.\n",
    "    isCache (bool) -- Flag. True loads images from cache, False overwrites cached images.\n",
    "        \n",
    "    Return: \n",
    "        pd.DataFrame with image objects and category encodings \n",
    "    \"\"\"\n",
    "    # Read in cached file, if exists\n",
    "    cache_path = '/test/cleaned_test.pkl' if isTest else '/test/cleaned_train.pkl'\n",
    "    if Path(cache_path).is_file() and isCache: \n",
    "        print(f\"Loading cache {'test' if isTest else 'train'} file\")\n",
    "        return pd.read_pickle(cache_path)    \n",
    "    \n",
    "    folder_name = '20_Validation' if isTest else folder_name\n",
    "    img_dir_path = Path(f\"{os.getcwd()}/{folder_name}.zip\") \n",
    "    \n",
    "    # Unzip folder\n",
    "    category_zip = zipfile.ZipFile(f\"{os.getcwd()}/{folder_name}.zip\")\n",
    "    category_zip.extractall(f\"{os.getcwd()}/{folder_name}/\")\n",
    "    \n",
    "    # Get info about image to use in dataframe\n",
    "    image_names, category_names, images, encoding = get_image_data(folder_name, img_dir_path, isTest)\n",
    "    df = create_cleaned_df(image_names, images, category_names, encoding)          \n",
    "    \n",
    "    # Cache dataframe\n",
    "    if not Path(cache_path).is_file() or isCache is False:\n",
    "        df.to_pickle(f\"./{cache_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(folder_name, img_dir_path, isTest):\n",
    "    \"\"\"\n",
    "    Returns lists of image names, category names, and image pixels of all images in folder. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    folder_name (string) -- path of image folder in root directory \n",
    "    img_dir_path (Path) -- path of image directory in root directory \n",
    "    isTest (bool) -- Flag. True loads images from test set, False loads train set.\n",
    "        \n",
    "    Return: \n",
    "        lists with image names, category names, and image objects \n",
    "    \"\"\"\n",
    "    image_names, category_names, images = [], [], []\n",
    "    \n",
    "    with ZipFile(img_dir_path, 'r') as images_zip: \n",
    "        for filename in images_zip.namelist(): \n",
    "            img_name = re.search(\"^.*.jpg\", filename)\n",
    "            \n",
    "            # Only include images that are no corrupted\n",
    "            if img_name is not None and \"/._\" not in img_name.group(): \n",
    "                if ' ' in img_name.group(): \n",
    "                    continue \n",
    "                image_names.append(img_name.group())\n",
    "            # Get image data in pixels for test files\n",
    "            if isTest: \n",
    "                img_path = Path(f\"{folder_name}/{img_name.group()}\")\n",
    "                images.append(io.imread(img_path))\n",
    "                continue \n",
    "            \n",
    "            # Get image category name and image data in pixels for train data\n",
    "            category_name = re.search(\"(.*)/\", filename)\n",
    "            if category_name and \"/._\" not in img_name.group(): \n",
    "                category_name = category_name.group().replace(\"/\", \"\")\n",
    "                category_names.append(category_name)\n",
    "                category_path = Path(f\"{folder_name}/{img_name.group()}\")\n",
    "                image = io.imread(category_path)\n",
    "                images.append(image)\n",
    "    \n",
    "    # Translate category name into encoding for train data\n",
    "    if not isTest:\n",
    "        encoding = encode_categories(category_names)\n",
    "        return image_names, category_names, images, encoding\n",
    "    return image_names, category_names, images, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categories(category_names):\n",
    "    \"\"\"\n",
    "    Returns list category encodings of all images in folder. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    category_names (list) -- category names of all images \n",
    "        \n",
    "    Return: \n",
    "        list with category name encodings of all images\n",
    "    \"\"\"\n",
    "    encoding_dict = {0:'airplanes', 1:'bear', 2:'blimp', 3:'comet', 4:'crab', \\\n",
    "                    5:'dog', 6:'dolphin', 7:'giraffe', 8:'goat', 9:'gorilla', \\\n",
    "                    10:'kangaroo', 11:'killer-whale', 12:'leopards', 13:'llama', \\\n",
    "                    14:'penguin', 15:'porcupine', 16:'teddy-bear', 17:'triceratops', \\\n",
    "                    18:'unicorn', 19:'zebra'}\n",
    "    # Flip key-value pairs \n",
    "    encoding_dict = {v: k for k, v in encoding_dict.items()}\n",
    "    return [encoding_dict[cat_name] for cat_name in category_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cleaned_df(image_names, images, category_names=None, encoding=None):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with picture objects and category encodings of all images in folder. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    image_names (list) -- name of all images\n",
    "    images (list) -- image objects of all images\n",
    "    category_names (list) -- category names of all images \n",
    "    encoding (list) -- category encodings of all images\n",
    "    \n",
    "    Return: \n",
    "        pd.DataFrame with image objects and category encodings \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame() \n",
    "    df['name'] = image_names\n",
    "    df['image'] = images\n",
    "    df['image'] = convert_gray(df['image'])\n",
    "    \n",
    "    # For train data, include response variable\n",
    "    if category_names and encoding:\n",
    "        df['category'] = category_names\n",
    "        df['encoding'] = encoding\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Clean data and measure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 13.93\n",
      "Training images loaded: 1501\n",
      "Test images loaded: 716\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "t1 = time.time()\n",
    "training_data = read_organize_data(isTest=False, isCache=True)\n",
    "validation_data = read_organize_data(isTest=True, isCache=True)\n",
    "t2 = time.time()\n",
    "print(f\"Seconds: {round(t2 - t1, 2)}\")\n",
    "print(f\"Training images loaded: {len(training_data)}\")\n",
    "print(f\"Test images loaded: {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"confirm\"></a>\n",
    "\n",
    "### Part 3. Confirm images are in proper RGB format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in correct RGB format!\n"
     ]
    }
   ],
   "source": [
    "# The following dataframe will have 0 entries if data is properly cleaned\n",
    "starting_data = read_organize_data(isTest=False, isCache=True)\n",
    "\n",
    "# Check for images in greyscale format\n",
    "if starting_data[starting_data['image'].apply(lambda x: len(x.shape) < 3)].empty:\n",
    "    print(\"Images in correct RGB format!\")\n",
    "else:\n",
    "    print(\"Images need to be correctly formatted!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
